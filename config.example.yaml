# AI Proxy Configuration Example

# Server bind address (default: 127.0.0.1, use 0.0.0.0 to listen on all interfaces)
bind: "127.0.0.1"

# Server listen port
listen: ":8642"

# Default max_tokens value for requests that don't specify one (default: 4096)
# This is used when converting requests to APIs that require max_tokens (e.g., Anthropic)
default_max_tokens: 4096

# Upstream services configuration
# Requests are load-balanced using weighted round-robin
# On 4xx/5xx errors, the next upstream is automatically tried
upstreams:
  - name: "runanytime"
    base_url: "https://runanytime.hxi.me"
    token: "sk-"
    weight: 10
    api_type: "anthropic"
    enabled: false
    # If this upstream only supports streaming responses, enable this to force stream=true upstream.
    # The proxy will convert the SSE stream back into a single JSON response for non-stream clients.
    must_stream: true
    # Model name mappings for this upstream
    # Key: client model name, Value: upstream model name
    model_mappings:
      "claude-4-5-haiku": "claude-haiku-4-5-20251001"
      "claude-4-5-haiku-thinking": "claude-haiku-4-5-20251001-thinking"
      "claude-4-5-opus": "claude-opus-4-5-20251101"
      "claude-4-5-opus-thinking": "claude-opus-4-5-20251101-thinking"
      "claude-4-5-sonnet": "claude-sonnet-4-5-20250929"
      "claude-4-5-sonnet-thinking": "claude-sonnet-4-5-20250929-thinking"
    # Available models (client model names, i.e., keys in model_mappings)
    # Only requests for these models will be routed to this upstream
    # If not specified, all models are accepted
    available_models:
      - "claude-4-5-haiku"
      - "claude-4-5-haiku-thinking"
      - "claude-4-5-sonnet"
      - "claude-4-5-sonnet-thinking"
      - "claude-4-5-opus"
      - "claude-4-5-opus-thinking"

  - name: "HotaruAPI"
    base_url: "https://api.hotaruapi.top"
    token: "sk-"
    weight: 5
    api_type: "anthropic"
    model_mappings:
      "claude-4-5-haiku": "claude-haiku-4-5-20251001"
      "claude-4-5-opus": "claude-opus-4-5-20251101"
      "claude-4-5-sonnet": "claude-sonnet-4-5-20250929"
      "claude-4-5-sonnet-thinking": "claude-sonnet-4-5-20250929-thinking"
    available_models:
      - "claude-4-5-haiku"
      - "claude-4-5-sonnet"
      - "claude-4-5-sonnet-thinking"
      - "claude-4-5-opus"

  - name: "Nyxar API"
    base_url: "https://api.nyxar.org"
    token: "sk-"
    weight: 5
    api_type: "anthropic"
    model_mappings:
      "claude-4-5-haiku": "claude-haiku-4-5-20251001"
      "claude-4-5-opus": "claude-opus-4-5-20251101"
      "claude-4-5-sonnet": "claude-sonnet-4-5-20250929"
    available_models:
      - "claude-4-5-haiku"
      - "claude-4-5-sonnet"
      - "claude-4-5-opus"
      
  - name: "Huan API"
    base_url: "https://ai.huan666.de"
    token: "sk-"
    weight: 1
    api_type: "anthropic"
    model_mappings:
      "claude-4-5-haiku": "claude-haiku-4-5-20251001"
      "claude-4-5-sonnet": "claude-sonnet-4-5-20250929"
    available_models:
      - "claude-4-5-haiku"
      - "claude-4-5-sonnet"

  - name: "123nhh"
    base_url: "https://new.123nhh.xyz"
    token: "sk-"
    weight: 1
    api_type: "anthropic"
    model_mappings:
      "claude-4-5-opus-thinking": "gemini-claude-opus-4-5-thinking"
      "claude-4-5-sonnet": "gemini-claude-sonnet-4-5"
    available_models:
      - "claude-4-5-opus-thinking"
      - "claude-4-5-sonnet"
      
  - name: "鸢北的公益站"
    base_url: "https://api.nlvps.hidns.co"
    token: "sk-"
    weight: 10
    api_type: "anthropic"
    model_mappings:
      "claude-4-5-sonnet": "claude-sonnet-4-5-20250929"
    available_models:
      - "claude-4-5-sonnet"

  # Example OpenAI-compatible upstream
  # Use api_type: "openai" for OpenAI-compatible services
  - name: "OpenAI Compatible"
    base_url: "https://api.openai.com"
    token: "sk-your-openai-key"
    weight: 5
    enabled: false
    api_type: "openai"  # Use OpenAI API format (Authorization: Bearer header, /v1/chat/completions endpoint)
    model_mappings:
      "gpt-4": "gpt-4-turbo"
      "gpt-4o": "gpt-4o-2024-11-20"
    available_models:
      - "gpt-4"
      - "gpt-4o"

  # Example OpenAI upstream with native Responses API support
  # Use api_type: "responses" for native /v1/responses endpoint
  - name: "OpenAI Responses"
    base_url: "https://api.openai.com"
    token: "sk-your-openai-key"
    weight: 5
    enabled: false
    api_type: "responses"  # Use native Responses API format (/v1/responses endpoint)
    model_mappings:
      "gpt-4o": "gpt-4o-2024-11-20"
    available_models:
      - "gpt-4o"

  # Example Gemini upstream
  # Use api_type: "gemini" for Google Gemini API
  - name: "Google Gemini"
    base_url: "https://generativelanguage.googleapis.com"
    token: "your-gemini-api-key"
    weight: 5
    enabled: false
    api_type: "gemini"  # Use Gemini API format (API key auth, /v1beta/models endpoint)
    model_mappings:
      "gemini-pro": "gemini-1.5-pro"
      "gemini-flash": "gemini-1.5-flash"
    available_models:
      - "gemini-pro"
      - "gemini-flash"
